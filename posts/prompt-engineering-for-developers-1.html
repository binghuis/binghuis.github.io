<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><title>Binghuis</title><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"/><meta name="next-head-count" content="3"/><meta charSet="utf-8"/><link rel="icon" href="/favicon.png"/><link rel="preload" href="/_next/static/css/bf10c7098905f5e4.css" as="style"/><link rel="stylesheet" href="/_next/static/css/bf10c7098905f5e4.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-8fa1640cc84ba8fe.js" defer=""></script><script src="/_next/static/chunks/framework-ac88a2a245aea9ab.js" defer=""></script><script src="/_next/static/chunks/main-f6b403feca12b39b.js" defer=""></script><script src="/_next/static/chunks/pages/_app-9b50272452f67b94.js" defer=""></script><script src="/_next/static/chunks/98-a8d03b3acab31698.js" defer=""></script><script src="/_next/static/chunks/pages/posts/%5Bslug%5D-0cc53cb44e670df6.js" defer=""></script><script src="/_next/static/HaHGZ2Jd8A2QCmRueQbn7/_buildManifest.js" defer=""></script><script src="/_next/static/HaHGZ2Jd8A2QCmRueQbn7/_ssgManifest.js" defer=""></script></head><body class="relative h-screen w-screen overflow-y-auto overflow-x-hidden scroll-smooth dark:bg-slate-950"><div id="__next"><div class="prose mx-auto px-4 pb-16 pt-16 laptop:max-w-4xl"><article class="dark:prose-invert"><nav><a class="text-lg" href="/">👈 back</a></nav><main class="mt-6"><h1>LLM 提示词最佳实践：简介</h1><div class="text-sm text-gray-500">2023-06-03</div><div class="text-base text-gray-500">吴恩达《ChatGPT Prompt Engineering for Developers》内容提炼</div><blockquote>
<p>本课程专注于帮助开发者使用 OpenAI API 调用 LLM（大型语言模型） 快速构建软件应用程序，而非 ChatGPT Web 的使用。</p>
</blockquote>
<h2>LLM（大语言模型） 类型</h2>
<ul>
<li>
<p>基础大模型：基于文本数据训练，训练出预测下一个单词能力的模型（可理解为”文字接龙“）。训练数据通常来自互联网。</p>
<p>例如：如果你输入提示“法国的首都是什么”，则基础 LLM 可能会根据互联网上的文章，将答案预测为“法国最大的城市是什么？
法国的人口是多少？”，因为互联网上的文章很可能是有关法国国家的问答题目列表。</p>
</li>
<li>
<p>指令调整型模型：指令调整的 LLMs 的训练通常是从已经训练好的基本 LLMs 开始，该模型已经在大量文本数据上进行了训练。
然后，使用输入是指令、输出是其应该返回的结果的数据集来对其进行微调，要求它遵循这些指令。然后通常使用一种称为
RLHF（reinforcement learning from human feedback，人类反馈强化学习）的技术进行进一步改进，使系统更能够有帮助地遵循指令。</p>
<p>因此，如果你问它，“法国的首都是什么？”，它更有可能输出“法国的首都是巴黎”。</p>
</li>
</ul>
<p>因为指令调整的 LLMs 已经被训练成有益、诚实和无害的，所以与基础 LLMs 相比，它们更不可能输出有害信息。</p>
<p>因此，本课程将重点介绍针对指令调整 LLM 的最佳实践，这是我们建议您用于大多数应用程序的。</p>
<blockquote>
<p>当您使用指令调整 LLM 时，请类似于考虑向另一个人提供指令，假设它是一个聪明但不知道您任务的具体细节的人。当 LLM 无法正常工作时，有时是因为指令不够清晰。</p>
</blockquote><div id="comments"></div></main></article></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"content":"var Component=(()=\u003e{var d=Object.create;var i=Object.defineProperty;var a=Object.getOwnPropertyDescriptor;var p=Object.getOwnPropertyNames;var u=Object.getPrototypeOf,M=Object.prototype.hasOwnProperty;var m=(e,n)=\u003e()=\u003e(n||e((n={exports:{}}).exports,n),n.exports),f=(e,n)=\u003e{for(var r in n)i(e,r,{get:n[r],enumerable:!0})},o=(e,n,r,l)=\u003e{if(n\u0026\u0026typeof n==\"object\"||typeof n==\"function\")for(let c of p(n))!M.call(e,c)\u0026\u0026c!==r\u0026\u0026i(e,c,{get:()=\u003en[c],enumerable:!(l=a(n,c))||l.enumerable});return e};var x=(e,n,r)=\u003e(r=e!=null?d(u(e)):{},o(n||!e||!e.__esModule?i(r,\"default\",{value:e,enumerable:!0}):r,e)),b=e=\u003eo(i({},\"__esModule\",{value:!0}),e);var L=m((C,s)=\u003e{s.exports=_jsx_runtime});var k={};f(k,{default:()=\u003e_,frontmatter:()=\u003eg});var t=x(L()),g={title:\"LLM \\u63D0\\u793A\\u8BCD\\u6700\\u4F73\\u5B9E\\u8DF5\\uFF1A\\u7B80\\u4ECB\",description:\"\\u5434\\u6069\\u8FBE\\u300AChatGPT Prompt Engineering for Developers\\u300B\\u5185\\u5BB9\\u63D0\\u70BC\",date:\"2023-06-3\"};function h(e){let n=Object.assign({blockquote:\"blockquote\",p:\"p\",h2:\"h2\",ul:\"ul\",li:\"li\"},e.components);return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsxs)(n.blockquote,{children:[`\n`,(0,t.jsx)(n.p,{children:\"\\u672C\\u8BFE\\u7A0B\\u4E13\\u6CE8\\u4E8E\\u5E2E\\u52A9\\u5F00\\u53D1\\u8005\\u4F7F\\u7528 OpenAI API \\u8C03\\u7528 LLM\\uFF08\\u5927\\u578B\\u8BED\\u8A00\\u6A21\\u578B\\uFF09 \\u5FEB\\u901F\\u6784\\u5EFA\\u8F6F\\u4EF6\\u5E94\\u7528\\u7A0B\\u5E8F\\uFF0C\\u800C\\u975E ChatGPT Web \\u7684\\u4F7F\\u7528\\u3002\"}),`\n`]}),`\n`,(0,t.jsx)(n.h2,{children:\"LLM\\uFF08\\u5927\\u8BED\\u8A00\\u6A21\\u578B\\uFF09 \\u7C7B\\u578B\"}),`\n`,(0,t.jsxs)(n.ul,{children:[`\n`,(0,t.jsxs)(n.li,{children:[`\n`,(0,t.jsx)(n.p,{children:\"\\u57FA\\u7840\\u5927\\u6A21\\u578B\\uFF1A\\u57FA\\u4E8E\\u6587\\u672C\\u6570\\u636E\\u8BAD\\u7EC3\\uFF0C\\u8BAD\\u7EC3\\u51FA\\u9884\\u6D4B\\u4E0B\\u4E00\\u4E2A\\u5355\\u8BCD\\u80FD\\u529B\\u7684\\u6A21\\u578B\\uFF08\\u53EF\\u7406\\u89E3\\u4E3A\\u201D\\u6587\\u5B57\\u63A5\\u9F99\\u201C\\uFF09\\u3002\\u8BAD\\u7EC3\\u6570\\u636E\\u901A\\u5E38\\u6765\\u81EA\\u4E92\\u8054\\u7F51\\u3002\"}),`\n`,(0,t.jsx)(n.p,{children:`\\u4F8B\\u5982\\uFF1A\\u5982\\u679C\\u4F60\\u8F93\\u5165\\u63D0\\u793A\\u201C\\u6CD5\\u56FD\\u7684\\u9996\\u90FD\\u662F\\u4EC0\\u4E48\\u201D\\uFF0C\\u5219\\u57FA\\u7840 LLM \\u53EF\\u80FD\\u4F1A\\u6839\\u636E\\u4E92\\u8054\\u7F51\\u4E0A\\u7684\\u6587\\u7AE0\\uFF0C\\u5C06\\u7B54\\u6848\\u9884\\u6D4B\\u4E3A\\u201C\\u6CD5\\u56FD\\u6700\\u5927\\u7684\\u57CE\\u5E02\\u662F\\u4EC0\\u4E48\\uFF1F\n\\u6CD5\\u56FD\\u7684\\u4EBA\\u53E3\\u662F\\u591A\\u5C11\\uFF1F\\u201D\\uFF0C\\u56E0\\u4E3A\\u4E92\\u8054\\u7F51\\u4E0A\\u7684\\u6587\\u7AE0\\u5F88\\u53EF\\u80FD\\u662F\\u6709\\u5173\\u6CD5\\u56FD\\u56FD\\u5BB6\\u7684\\u95EE\\u7B54\\u9898\\u76EE\\u5217\\u8868\\u3002`}),`\n`]}),`\n`,(0,t.jsxs)(n.li,{children:[`\n`,(0,t.jsx)(n.p,{children:`\\u6307\\u4EE4\\u8C03\\u6574\\u578B\\u6A21\\u578B\\uFF1A\\u6307\\u4EE4\\u8C03\\u6574\\u7684 LLMs \\u7684\\u8BAD\\u7EC3\\u901A\\u5E38\\u662F\\u4ECE\\u5DF2\\u7ECF\\u8BAD\\u7EC3\\u597D\\u7684\\u57FA\\u672C LLMs \\u5F00\\u59CB\\uFF0C\\u8BE5\\u6A21\\u578B\\u5DF2\\u7ECF\\u5728\\u5927\\u91CF\\u6587\\u672C\\u6570\\u636E\\u4E0A\\u8FDB\\u884C\\u4E86\\u8BAD\\u7EC3\\u3002\n\\u7136\\u540E\\uFF0C\\u4F7F\\u7528\\u8F93\\u5165\\u662F\\u6307\\u4EE4\\u3001\\u8F93\\u51FA\\u662F\\u5176\\u5E94\\u8BE5\\u8FD4\\u56DE\\u7684\\u7ED3\\u679C\\u7684\\u6570\\u636E\\u96C6\\u6765\\u5BF9\\u5176\\u8FDB\\u884C\\u5FAE\\u8C03\\uFF0C\\u8981\\u6C42\\u5B83\\u9075\\u5FAA\\u8FD9\\u4E9B\\u6307\\u4EE4\\u3002\\u7136\\u540E\\u901A\\u5E38\\u4F7F\\u7528\\u4E00\\u79CD\\u79F0\\u4E3A\nRLHF\\uFF08reinforcement learning from human feedback\\uFF0C\\u4EBA\\u7C7B\\u53CD\\u9988\\u5F3A\\u5316\\u5B66\\u4E60\\uFF09\\u7684\\u6280\\u672F\\u8FDB\\u884C\\u8FDB\\u4E00\\u6B65\\u6539\\u8FDB\\uFF0C\\u4F7F\\u7CFB\\u7EDF\\u66F4\\u80FD\\u591F\\u6709\\u5E2E\\u52A9\\u5730\\u9075\\u5FAA\\u6307\\u4EE4\\u3002`}),`\n`,(0,t.jsx)(n.p,{children:\"\\u56E0\\u6B64\\uFF0C\\u5982\\u679C\\u4F60\\u95EE\\u5B83\\uFF0C\\u201C\\u6CD5\\u56FD\\u7684\\u9996\\u90FD\\u662F\\u4EC0\\u4E48\\uFF1F\\u201D\\uFF0C\\u5B83\\u66F4\\u6709\\u53EF\\u80FD\\u8F93\\u51FA\\u201C\\u6CD5\\u56FD\\u7684\\u9996\\u90FD\\u662F\\u5DF4\\u9ECE\\u201D\\u3002\"}),`\n`]}),`\n`]}),`\n`,(0,t.jsx)(n.p,{children:\"\\u56E0\\u4E3A\\u6307\\u4EE4\\u8C03\\u6574\\u7684 LLMs \\u5DF2\\u7ECF\\u88AB\\u8BAD\\u7EC3\\u6210\\u6709\\u76CA\\u3001\\u8BDA\\u5B9E\\u548C\\u65E0\\u5BB3\\u7684\\uFF0C\\u6240\\u4EE5\\u4E0E\\u57FA\\u7840 LLMs \\u76F8\\u6BD4\\uFF0C\\u5B83\\u4EEC\\u66F4\\u4E0D\\u53EF\\u80FD\\u8F93\\u51FA\\u6709\\u5BB3\\u4FE1\\u606F\\u3002\"}),`\n`,(0,t.jsx)(n.p,{children:\"\\u56E0\\u6B64\\uFF0C\\u672C\\u8BFE\\u7A0B\\u5C06\\u91CD\\u70B9\\u4ECB\\u7ECD\\u9488\\u5BF9\\u6307\\u4EE4\\u8C03\\u6574 LLM \\u7684\\u6700\\u4F73\\u5B9E\\u8DF5\\uFF0C\\u8FD9\\u662F\\u6211\\u4EEC\\u5EFA\\u8BAE\\u60A8\\u7528\\u4E8E\\u5927\\u591A\\u6570\\u5E94\\u7528\\u7A0B\\u5E8F\\u7684\\u3002\"}),`\n`,(0,t.jsxs)(n.blockquote,{children:[`\n`,(0,t.jsx)(n.p,{children:\"\\u5F53\\u60A8\\u4F7F\\u7528\\u6307\\u4EE4\\u8C03\\u6574 LLM \\u65F6\\uFF0C\\u8BF7\\u7C7B\\u4F3C\\u4E8E\\u8003\\u8651\\u5411\\u53E6\\u4E00\\u4E2A\\u4EBA\\u63D0\\u4F9B\\u6307\\u4EE4\\uFF0C\\u5047\\u8BBE\\u5B83\\u662F\\u4E00\\u4E2A\\u806A\\u660E\\u4F46\\u4E0D\\u77E5\\u9053\\u60A8\\u4EFB\\u52A1\\u7684\\u5177\\u4F53\\u7EC6\\u8282\\u7684\\u4EBA\\u3002\\u5F53 LLM \\u65E0\\u6CD5\\u6B63\\u5E38\\u5DE5\\u4F5C\\u65F6\\uFF0C\\u6709\\u65F6\\u662F\\u56E0\\u4E3A\\u6307\\u4EE4\\u4E0D\\u591F\\u6E05\\u6670\\u3002\"}),`\n`]})]})}function j(e={}){let{wrapper:n}=e.components||{};return n?(0,t.jsx)(n,Object.assign({},e,{children:(0,t.jsx)(h,e)})):h(e)}var _=j;return b(k);})();\n;return Component;","frontmatter":{"title":"LLM 提示词最佳实践：简介","description":"吴恩达《ChatGPT Prompt Engineering for Developers》内容提炼","date":"2023-06-03"},"slug":"prompt-engineering-for-developers-1"},"__N_SSG":true},"page":"/posts/[slug]","query":{"slug":"prompt-engineering-for-developers-1"},"buildId":"HaHGZ2Jd8A2QCmRueQbn7","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>